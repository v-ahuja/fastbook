{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.11\r\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "!pip install -Uqq fastbook\n",
    "import fastbook\n",
    "fastbook.setup_book()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from fastbook import *\n",
    "from fastai.vision.widgets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "??verify_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From Model to Production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Practice of Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting Your Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The State of Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computer vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text (natural language processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining text and images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tabular data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recommendation systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Drivetrain Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# clean\n",
    "To download images with Bing Image Search, sign up at [Microsoft Azure](https://azure.microsoft.com/en-us/services/cognitive-services/bing-web-search-api/) for a free account. You will be given a key, which you can copy and enter in a cell as follows (replacing 'XXX' with your key and executing it):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ddg_search\n",
    "\n",
    "image_urls = ddg_search.search_images_ddg(\"dachshund\")\n",
    "image_urls = L(image_urls)\n",
    "image_urls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest = Path(\"dachshund\")\n",
    "if not dest.exists():\n",
    "    dest.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_url(image_urls[0], \"dachshund/test_dachshund.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open(\"dachshund/test_dachshund.jpg\")\n",
    "im.to_thumb(128,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_images(dest, urls=image_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fns = get_image_files(dest)\n",
    "type(fns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bear_fns = get_image_files(\"../bears\")\n",
    "fns.extend(bear_fns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed = verify_images(fns)\n",
    "failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed.map(Path.unlink);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sidebar: Getting Help in Jupyter Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End sidebar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Data to DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc(TensorImage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing transformations\n",
    "\n",
    "img = Image.open(fns[0])\n",
    "# im_t = cast(array(img), TensorImage)\n",
    "\n",
    "timg = TensorImage(array(img)).permute(2,0,1).float()/255.\n",
    "def _batch_ex(bs): return TensorImage(timg[None].expand(bs, *timg.shape).clone())\n",
    "\n",
    "imgs = _batch_ex(5)\n",
    "# deflt = Flip()\n",
    "# show_images( deflt(imgs) ,suptitle='Default Flip')\n",
    "\n",
    "# tfm()\n",
    "\n",
    "transformed = []\n",
    "\n",
    "for tfm in tfms:\n",
    "#     print(f'item = {item}. type = {type(item)}\\n')\n",
    "    transformed_images = tfm(imgs)\n",
    "    for image in transformed_images:\n",
    "        transformed.append(image)\n",
    "\n",
    "show_images(transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The ImageDataLoaders allow one to load data and transform it.\n",
    "# item_tfms : All images need to be same size. Randomly snapshot different sections of the same image instead of other\n",
    "#             methods which will cause loss of information\n",
    "# seed : Affects train/validation split.\n",
    "# batch_tfms\n",
    "block = DataBlock(blocks = (ImageBlock,CategoryBlock),\n",
    "                  get_items=get_image_files,\n",
    "                  splitter = RandomSplitter(seed=42),\n",
    "                  get_y=parent_label,\n",
    "                  item_tfms=RandomResizedCrop(224))\n",
    "\n",
    "block = block.new(item_tfms=RandomResizedCrop(224, min_scale=0.5), batch_tfms=aug_transforms(mult=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = block.dataloaders(\"images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc(DataBlock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc(ImageDataLoaders.from_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.valid.show_batch(max_n=8, nrows=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Your Model, and Using It to Clean Your Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = cnn_learner(dls, resnet34, metrics=error_rate)\n",
    "learner.fine_tune(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fns[0].parent.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learner)\n",
    "interp.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.plot_top_losses(5, nrows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner = ImageClassifierCleaner(learn)\n",
    "cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# for idx in cleaner.delete(): cleaner.fns[idx].unlink()\n",
    "# for idx,cat in cleaner.change(): shutil.move(str(cleaner.fns[idx]), path/cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turning Your Model into an Online Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the Model for Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path()\n",
    "path.ls(file_exts='.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_inf = load_learner(path/'export.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_inf.predict('../images/grizzly.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_inf.dls.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Notebook App from the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btn_upload = FileUpload()\n",
    "btn_upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# For the book, we can't actually click an upload button, so we fake it\n",
    "btn_upload = SimpleNamespace(data = ['images/grizzly.jpg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = PILImage.create(btn_upload.data[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_pl = widgets.Output()\n",
    "out_pl.clear_output()\n",
    "with out_pl:\n",
    "    display(img.resize((224,224)))\n",
    "out_pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred,pred_idx,probs = learn_inf.predict(img)\n",
    "print(f'Prediction: {pred}; pred_idx = {pred_idx}; probs = {probs}')\n",
    "f'Prediction: {pred}; Probability: {probs[pred_idx]:.04f}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_pred = widgets.Label()\n",
    "lbl_pred.value = f'Prediection: {pred}; Probability: {probs[pred_idx]:0.04f}'\n",
    "lbl_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btn_run = widgets.Button(description=\"Classify\")\n",
    "btn_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_click_classify():\n",
    "    img = btn_upload.data[-1]\n",
    "    out_pl.clear_output()\n",
    "    with out_pl:\n",
    "        display(img.resize(224,224))\n",
    "    prediction, pred_idx, probs = learn_inf.predict(img)\n",
    "    lbl_pred.value = f'prediction = {prediction}; Probability = {pros[pred_idx]:0.04f}'\n",
    "    \n",
    "btn_run.on_click(on_click_classify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#Putting back btn_upload to a widget for next cell\n",
    "btn_upload = widgets.FileUpload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VBox([widgets.Label(\"Select your dashchund\"), btn_upload,  btn_run, out_pl, lbl_pred])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turning Your Notebook into a Real App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# !pip install voila\n",
    "# !jupyter serverextension enable --sys-prefix voila "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploying your app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Avoid Disaster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unforeseen Consequences and Feedback Loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Writing!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questionnaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Provide an example of where the bear classification model might work poorly in production, due to structural or style differences in the training data.\n",
    "Printed image for example\n",
    "\n",
    "1. Where do text models currently have a major deficiency?\n",
    "while classification is very good with text models, summarizing, translation or generation of correct text is not very good. For example, right now there's no good way to generate accurate medical respones/information.\n",
    "\n",
    "1. What are possible negative societal implications of text generation models?\n",
    "It's very easy to generate contextually appropriate text, but hard to recognize when text has been generated by a computer or whether text is correct. Therefore it can be used to spread disinformation\n",
    "\n",
    "1. In situations where a model might make mistakes, and those mistakes could be harmful, what is a good alternative to automating a process?\n",
    "Pairing model with human to make human more efficient.\n",
    "\n",
    "1. What kind of tabular data is deep learning particularly good at?\n",
    "natural language in columns or high cardinality categorical variables such as zip code\n",
    "\n",
    "1. What's a key downside of directly using a deep learning model for recommendation systems?\n",
    "take longer to train\n",
    "\n",
    "1. What are the steps of the Drivetrain Approach?\n",
    "Start with _clear_ objective, then look at _levers_ you can pull to better achieve that objective, then consider the _data_ needed for achieving objective.\n",
    "\n",
    "1. How do the steps of the Drivetrain Approach map to a recommendation system?\n",
    "\n",
    "1. Create an image recognition model using data you curate, and deploy it on the web.\n",
    "\n",
    "1. What is `DataLoaders`?\n",
    "`DataLoaders` is a light-weight class that stores all the `DataLoader` objects making them available as `train` and `valid`\n",
    "\n",
    "1. What four things do we need to tell fastai to create `DataLoaders`?\n",
    "- Where to load data from\n",
    "- how to label data\n",
    "- train/validation split\n",
    "- what type of data it is\n",
    "\n",
    "\n",
    "1. What does the `splitter` parameter to `DataBlock` do?\n",
    "split to train/validation\n",
    "\n",
    "1. How do we ensure a random split always gives the same validation set?\n",
    "`seed`\n",
    "\n",
    "1. What letters are often used to signify the independent and dependent variables?\n",
    "`y` and `x` \n",
    "\n",
    "1. What's the difference between the crop, pad, and squish resize approaches? When might you choose one over the others?\n",
    "`crop` randomly crops a section of the image\n",
    "`pad` will pad with black/white space\n",
    "`squish` will squish the image to make it fit\n",
    "\n",
    "1. What is data augmentation? Why is it needed?\n",
    "Transform the data in different ways to help the model recognize different variations of the data.\n",
    "\n",
    "1. What is the difference between `item_tfms` and `batch_tfms`?\n",
    "`item_tfms` needs to do the transformation on each image individually\n",
    "once all images are of same size transformations can be done using gpu using `batch_tfms`\n",
    "\n",
    "1. What is a confusion matrix?\n",
    "way to visualize output of the train/validation process\n",
    "\n",
    "1. What does `export` save?\n",
    "pickled moidel\n",
    "\n",
    "1. What is it called when we use a model for getting predictions, instead of training?\n",
    "inference\n",
    "\n",
    "1. What are IPython widgets?\n",
    "IPython widgets are used to create UI widgets in jupyter notebooks by combining javascript and python\n",
    "\n",
    "1. When might you want to use CPU for deployment? When might GPU be better?\n",
    "once model is trained, it's just a function that's being called and therefore if high parallelization isn't needed, cpu is better because it's cheaper and more widely available. gpu might be needed when high parallelization is needed.\n",
    "\n",
    "1. What are the downsides of deploying your app to a server, instead of to a client (or edge) device such as a phone or PC?\n",
    "- has to always be up and running instead of just when the client needs it\n",
    "- managing machines\n",
    "- security considerations transferring data back and forth\n",
    "\n",
    "\n",
    "1. What are three examples of problems that could occur when rolling out a bear warning system in practice?\n",
    "- not enough diversity images\n",
    "\n",
    "1. What is \"out-of-domain data\"?\n",
    "- data not present in the training set\n",
    "\n",
    "1. What is \"domain shift\"?\n",
    "- over time the domain may change\n",
    "\n",
    "1. What are the three steps in the deployment process?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Consider how the Drivetrain Approach maps to a project or problem you're interested in.\n",
    "1. When might it be best to avoid certain types of data augmentation?\n",
    "1. For a project you're interested in applying deep learning to, consider the thought experiment \"What would happen if it went really, really well?\"\n",
    "1. Start a blog, and write your first blog post. For instance, write about what you think deep learning might be useful for in a domain you're interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
